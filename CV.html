

<div class="introduction">
    <h2>CV Summary</h2>
    <p>
      Highly motivated MSc student at The Technical University of Denmark (DTU) with a strong foundation in machine learning and computer vision, demonstrated by a 11.7/12.0 GPA and a WACV24 publication. Seeking a PhD to advance research in computer vision, building upon experience in synthetic data generation and deep learning for computer vision.
    </p>
  </div>
  
  <h2>Work History</h2>
  
  <h3>Student Assistant</h3>
  <p>Novo Nordisk (2022-present)</p>
  <p>Deep Learning in Computer Vision and Synthetic Data Generation.</p>
  <ul>
    <li> Developed and implemented a procedural synthetic data generation pipeline
    <li> Lead efforts to build a computer vision system to monitor aseptic behavior
  <p>Skills: Model development, ML-ops, documentation, version control, cloud
  computing.</p>
  </ul>
  
  <h3>Teaching Assistant</h3>
  <p>TA: Computational Tools for Data Science. DTU (2022)
  <ul>
    <li>I got a rating of 4.6/5 from course evaluations the course got a general rating of 2.4/5. (higher is better)
  </ul>

  
  <p>TA: Introduction to Machine Learning and Data Mining. DTU (2021)
  <ul>
    <li>I got a rating of 4.3/5 from course evaluations the course got a general rating of 4.0/5. (higher is better)
  </ul>
  <div class="job">
    <h3>Substitute Teacher</h3>
    <p>Vangeboskolen - Søllerød (2018-2019)</p>
    <p>In my gap year, I worked as a substitute teacher at a public school. Amongst other responsibilities, I was a full-time replacement in English and French for a 7th-grade class. <insert Add a sentence or two about transferable skills gained here.></p>
   
  <h2>Education</h2>
  <div class="degree">
    <h3>Bachelor of Science</h3>
    <p>DTU, Lyngby (2019 - 2023)</p>
    <p>Strategic Analysis and System Design (GPA: 10.2/12.0) <insert Add relevant coursework here.></p>
  </div>
  <div class="degree">
    <h3>Master of Science</h3>
    <p>DTU, Lyngby (2023 - 2025)</p>
    <p>Mathematical Modelling and Computation (GPA: 11.7/12.0)<br /><br />
        
    Exchange Semester at TUM<br />List of courses:<br />NLP<br />Computer vision III<br />DLinVC<br />3D vision Seminar <insert add a sentence or two about what you gained from the TUM exchange semester.></p>
  </div>
  
  <h2>Publications and Presentations</h2>
  <ul>
  <div class="publication">
    <h3>CrashCar101: Procedural Generation for Damage Assessment</h3>
    <p>IEEE/CVF Winter Conference on Applications of Computer Vision (2024)</p>
    <p><a href="https://crashcar.compute.dtu.dk">https://crashcar.compute.dtu.dk</a></p>
    <p><insert Add a brief description of the key contributions here.></p>
  </div>
  <div class="publication">
    <h3>Oral presentation of CrashCar101</h3>
    <p>Danish Digitalization, Data Science and AI 1.0 (2024)</p>
    <p><insert Add a brief description of the key contributions here.></p>
    <h3>Oral presentation of Diffusion Augmentation for Improved Object Detection</h3>
    <p>Danish Digitalization, Data Science and AI 2.0 (2024)</p>
    <p><a href="https://github.com/JensPars/ADLCV">https://github.com/JensPars/ADLCV</a></p>
    <p><insert Add a brief description of the key contributions here.></p>
  </div>
</ul>
  
  <h2>Academic Projects</h2>
  
  <ul>
    <li>
      <strong>Clothes Segmentation and Retrieval using DNN:</strong>
      <ul>
        <li>Implemented image segmentation on fashion images for feature similarity computation and information retrieval.</li>
        <li>Developed a deep convolutional network for attribute prediction, enabling independent item comparison.</li>
        <li>Built a deep convolutional network for semantic segmentation to isolate clothing items.</li>
        <li>Demonstrated the efficacy of using segmentation masks for improved attribute classification.</li>
        <li>Achieved consistent semantic segmentation using a deep neural network.</li>
      </ul>
    <li>
      <strong>Roskilde Festival: Counting People using Computer Vision:</strong>
      <ul>
      <li>Implemented Object detection model with tracking algorithm for counting people entering areas
      <li>Implemented acquisition setup and compute pipeline for live monitoring
    </ul>
    </li>
    <li>
      <strong>Deep Learning: Car Part Segmentation:</strong>
      <ul>
        <li>Addressed the challenge of automated car damage assessment using semantic segmentation in the insurance industry.</li>
        <li>Utilized transfer learning to enhance car damage location detection due to limited annotated data.</li>
        <li>Employed a pre-trained DeepLabv3 architecture with a ResNet backbone for car part and damage semantic segmentation.</li>
        <li>Implemented a suitable loss function to optimize model performance.</li>
        <li>Demonstrated significant improvement in pixel accuracy and dice score through transfer learning.</li>
        <li>Demonstrated significant improvement in pixel accuracy and dice score through the use of focal loss as apposed to cross entropy.</li>
      </ul>
  
    </li>
    <li>
      <strong>Comprehensive Synthetic Image Generation for Car Part and Damage Segmentation:</strong>
      <ul>
      <li>Addressed the challenge of vehicle damage assessment, requiring both damage localization and part identification.</li>
      <li>Tackled the problem of limited annotated real-world data by leveraging synthetic data generation.</li>
      <li>Developed a procedural generation pipeline to create damaged 3D car models and render corresponding 2D images with pixel-accurate annotations.</li>
      <li>Generated the CrashCar101 dataset, providing a large and varied training set without manual annotation.</li>
      <li>Validated the approach by conducting experiments on three real-world datasets for part and damage segmentation.</li>
      <li>Demonstrated that models trained on a combination of real and synthetic data outperformed models trained solely on real data for part segmentation.</li>
      <li>Showed the effectiveness of sim2real transfer learning for damage segmentation using the CrashCar101 dataset.</li>
    </ul>
    </li>
    <li>
      <strong>Exploring Synthetic Data Generation to Damage Anything:</strong>
      <ul>
      <li>Developed a comprehensive taxonomy of damage types and materials by leveraging generative language models.</li>
      <li>Generated hundreds of thousands of damage descriptions for diverse materials, effectively expanding the scope of damage representation.</li>
      <li>Utilized embedding techniques and clustering algorithms to organize the generated damage descriptions into a structured and coherent taxonomy.</li>
      <li>Investigated the capabilities of Large Vision Models (LVMs) in classifying and generating damage.</li>
      <li>Compiled a dataset of approximately 50 images showcasing various damage types to evaluate LVM performance.</li>
      <li>Employed VLMs to successfully classify the damage types present in the collected image dataset.</li>
      <li>Generated diverse and realistic damage types using generative image models.</li>
      <li>Concluded that LVMs demonstrate proficiency in both recognizing and generating damage, highlighting their potential for damage assessment applications.</li>
    </ul>
    </li>
    <li>
      <strong>Diffusion Augmentation for Improved Object Detection:</strong>
      <ul>
      <li>Investigated the effectiveness of augmenting real image datasets with synthetically generated instances (copy-pasting) to enhance object detection model performance.</li>
      <li>Evaluated various strategies for synthetic instance generation and presented preliminary results on model improvement.</li>
      <li>Experimented with diverse methods to increase the diversity and realism of the generated synthetic instances, focusing on visual fidelity.</li>
      <li>Explored different techniques for generating synthetic instances along with accurate segmentation masks, enabling precise integration into real images.</li>
      </ul>
    </li>
    <li>
      <strong>Comprehensive Review of Inverse Rendering Benchmarks:</strong>
      <ul>
        <li>Conducted a comprehensive review of inverse rendering benchmarks, encompassing both synthetic and real-world datasets.</li>
        <li>Analyzed the challenges of inverse rendering, highlighting its ill-posed nature and the need for accurate ground truth data.</li>
        <li>Examined the evolution of benchmarks from intrinsic image decomposition to full scene reconstruction, emphasizing the increasing complexity of ground truth measurements.</li>
        <li>Evaluated synthetic datasets like Oxholm et al., ShapeNet-Intrinsics, NeRD, and ABO, noting their advantages in providing flawless ground truth but limitations in representing real-world complexity.</li>
        <li>Reviewed real-world datasets such as MIT Intrinsics, DiLiGenT-MV, DTU-MVS, ReNe, OpenIllumination, NeRD (real subset), NeROIC, and Stanford-ORB, highlighting their contributions to evaluating various inverse rendering tasks (geometry estimation, relighting, novel view synthesis).</li>
        <li>Compared the strengths and weaknesses of different datasets, considering factors such as capture setup, ground truth accuracy, and the range of materials and lighting conditions.</li>
        <li>Documented the shift from controlled studio captures to in-the-wild scenarios, reflecting the increasing focus on real-world applicability of inverse rendering algorithms.</li>
        <li>Provided a detailed analysis of the capture setups, ground truth acquisition methods, and evaluation metrics used in each benchmark.</li>
      </ul>
    </li>
    <li>
      <strong>Segmentation of 3DGS using Foundation Models with Uncertainty:</strong>
      <p><insert Briefly describe the project's goal, your methods, and results here. Focus on your specific contributions. Explain what 3DGS is if needed.></p>
    </li>
  </ul>
  
  <h2>Conferences and Extracurricular Academic Preparation</h2>
  
  <h3>Conferences</h3>
  <ul>
    <li>
      <strong>WACV 2024:</strong> Paper published and poster presentation, networking.
    </li>
    <li>
      <strong>Danish Digitalization, Data Science and AI 1.0 (2024):</strong> Poster presentation and oral presentation at Synthetic Data Workshop, networking.
    </li>
    <li>
      <strong>Danish Digitalization, Data Science and AI 2.0 (2024):</strong> Oral presentation at Synthetic Data Workshop, networking.
    </li>
  </ul>
  
  <h3>Extracurricular Academic Preparation</h3>
  <ul>
    <li>
      <strong>ProbAI 2024 PhD Summer School (Copenhagen):</strong>
        <ul>
            <li><strong>Advanced Probabilistic AI Training:</strong> 5-day program covering key topics like variational inference and deep generative models.</li>
            <li><strong>Expert-Led, Collaborative Learning:</strong> Immersive environment with leading researchers from Aalborg University and NTNU.</li>
        </ul>
    </li>
    <li>
      <strong>DDSA Pre-grad Retreat 2024</strong> <insert Expand on what you gained from this experience here.>
    </li>
  </ul>
  
  <h2>Plans to publish...</h2>
  <p>
    Diffusion Augmentation for Improved Object Detection<br />
    Review of SOTA Inverse Rendering<insert Add a sentence about the current progress of these publications.>.
  </p>
  
  <h2>Skills</h2>
  <p>
      <insert Add a skills section here. Include skills such as: Programming languages (Python, etc.), Deep learning frameworks (TensorFlow, PyTorch), Computer vision libraries (OpenCV), Machine learning algorithms, Data analysis and visualization tools, Cloud computing platforms (AWS, Azure, GCP), Version control (Git), Research skills (data collection, analysis, etc.).>
  </p>
    
  </div>
  